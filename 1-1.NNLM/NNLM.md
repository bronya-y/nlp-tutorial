# NNLM

- 预测下一个词

---

### 语言模型

- 基于统计学习的语言模型
  - 求p(w1,w2,w3...,wm)出现的概率，则=p(w1)*p(w2|w1)*p(w3|w1,w2)....p(wm|w1,w2...,wm-1)
- n元模型
  - 忽略长度超过n的上文词的影响
  - p(wi|w1,w2,wi-1) = p(wi|wi-(n-1),...wi-1)
  - 一元模型，互相独立了

### 流程

- 首先有前n个词，要预测下一个词
- 把词转词向量
- 把词向量首尾拼接
- 进入全连接层
- 加tanh激活函数
- 全连接层
- 输出的节点代表下一个词语为i（索引）的概率
- 最后softMax函数归一化

### 代码

> 先embedding,再展平得到输入，输入进mlp进激活函数进两次
>
> 展平的输入进一次mlp进激活函数
>
> 把两次的相加
>
> 得到网络输出

---

### 总结(新)

- n元语言模型
  - 从前n个预测下一个
- 有一个（类似）直连的边
  - 类似resNet，但是加了一层MLP投影
  - 作者说可以加速收敛

---

